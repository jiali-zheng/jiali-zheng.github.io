<!DOCTYPE html>
<html>
<head>
  <link rel="icon" href="./static/images/icon.png">
  <meta charset="utf-8">
  <meta name="description"
        content="Design2Cloth: 3D Cloth Generation from 2D Masks">
  <meta name="keywords" content="Cloth, 3D, Generation, Design">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Design2Cloth: 3D Cloth Generation from 2D Masks</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Design2Cloth: 3D Cloth Generation from 2D Masks</h1>          
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="">Jiali Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Rolandos Alexandros Potamias</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.imperial.ac.uk/people/s.zafeiriou">Stefanos Zafeiriou</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Imperial College London, United Kingdom</span>
  
          </div>
          <br>
          <span class="author-block">
            <h1 class="title is-size-4  publication-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</h1>
          </span>
          <br>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Potamias_Handy_Towards_a_High_Fidelity_3D_Hand_Shape_and_Appearance_CVPR_2023_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2112.00585"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/F4hTHKZ8JNM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
               </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/rolpotamias/handy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Models</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_fig.jpg" alt="method" class="center">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, there has been a significant shift in the field of digital avatar research, towards modeling, animating and reconstructing clothed human representations, as a key step towards creating realistic avatars. However, current methods for 3D cloth generative models are garment specific or trained completely on synthetic data, hence lacking fine details and realism. In this work, we make a step towards automatic realistic garment design and propose Design2Cloth, a high fidelity 3D generative model trained on a real world dataset from more than 2200 subject scans. To provide vital contribution to the fashion industry, we developed a user-friendly adversarial model capable of generating diverse and detailed clothes simply by drawing a 2D cloth mask. Under a series of both qualitative and quantitative experiments, we showcase that Design2Cloth outperforms current state-of-the-art cloth generative models by a large margin. In addition to the generative properties of our network, we showcase that the proposed method can be used to achieve high quality reconstructions from single in-the-wild images and 3D scans.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">CVPR 2024 Presentation</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/F4hTHKZ8JNM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>

          </iframe>

        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
    <!-- Method overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
        <p>
            Handy is a large-scale shape and appearance model of the human hand. Handy is composed by 1208 subjects with various ages and ethnicities, tackling the limitation of previous models to accurately model diverse hands. 
        </p>
        <div>
            <img src="./static/images/handy.png" alt="method" class="center">
          </div>
        <p>
           To create Handy, we initially register the raw scans to a common template and then we apply Principal Component Analysis to model hand shape variations. In order to model the hand appearance we utilize a style-based GAN trained on the UV textures of hands. The proposed model manages to achieve photorealistic reconstructions. 
        </p>
          </div>
          <div>
            <img src="./static/images/recon.png" alt="method" class="center">
          </div>
      </div>
    </div>
  </div>
</section>
  
<!--  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Zheng_2024_CVPR,
      author    = {Zheng, Jiali and Potamias, Rolandos Alexandros and Zafeiriou, Stefanos},
      title     = {Design2Cloth: 3D Cloth Generation from 2D Masks},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2024},
      pages     = {4670-4680}
  }
</code></pre>
  </div>
</section>
-->

<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
