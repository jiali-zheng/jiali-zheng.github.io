<!DOCTYPE html>
<html>
<head>
  <link rel="icon" href="./static/images/icon.png">
  <meta charset="utf-8">
  <meta name="description"
        content="Design2Cloth: 3D Cloth Generation from 2D Masks">
  <meta name="keywords" content="Cloth, 3D, Generation, Design">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Design2Cloth: 3D Cloth Generation from 2D Masks</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Design2Cloth: 3D Cloth Generation from 2D Masks</h1>          
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="">Jiali Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/rolpotamias">Rolandos Alexandros Potamias</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.imperial.ac.uk/people/s.zafeiriou">Stefanos Zafeiriou</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Imperial College London, United Kingdom</span>
  
          </div>
          <br>
          <span class="author-block">
            <h1 class="title is-size-4  publication-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</h1>
          </span>
          <br>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.02686"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <!-- <span class="link-block">
               
                <a href="https://arxiv.org/abs/2112.00585"
                   class="external-link button is-normal is-rounded is-dark">
              
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://www.dropbox.com/scl/fi/93hlshwsg88bgd28hnu75/D2C_Dataset.zip?rlkey=usbr09pjimz9u0jrhigvbw062&st=jy1hcjmg&dl=0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
<!--                       <i class="fab fa-youtube"></i> -->
                    <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
               </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://jiali-zheng.github.io/Design2Cloth/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Models(TBA)</span>
                  </a>
             
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_fig.jpg" alt="method" class="center">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, there has been a significant shift in the field of digital avatar research, towards modeling, animating and reconstructing clothed human representations, as a key step towards creating realistic avatars. However, current methods for 3D cloth generative models are garment specific or trained completely on synthetic data, hence lacking fine details and realism. In this work, we make a step towards automatic realistic garment design and propose Design2Cloth, a high fidelity 3D generative model trained on a real world dataset from more than 2000 subject scans. To provide vital contribution to the fashion industry, we developed a user-friendly adversarial model capable of generating diverse and detailed clothes simply by drawing a 2D cloth mask. Under a series of both qualitative and quantitative experiments, we showcase that Design2Cloth outperforms current state-of-the-art cloth generative models by a large margin. In addition to the generative properties of our network, we showcase that the proposed method can be used to achieve high quality reconstructions from single in-the-wild images and 3D scans.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">CVPR 2024 Presentation</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/cfk6Zrwk31Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>

          </iframe>

        </div>
      </div>
    </div> 
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
    <!-- Method overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
        <p>
            Design2Cloth is a large-scale style and shape model of cloths. Design2Cloth is composed by more than 2000 unique garments worn by 2010 distinct identities with various genders, ages, heights and weights. The model enables modeling and generation of diverse and highly detailed clothes tackling the limitation of previous models to accurately model diverse cloths that follow the real-world distribution.
        </p>
        <div>
            <img src="./static/images/intp.png" alt="method" class="center">
          </div>
        <p>
           To create Design2Cloth, we built an automated pipeline to extract cloth meshes from the collected subject scans. We utilized the triplane representation and a dual-resolution discriminator to model various styles and enforce wrinkle details of the generated cloths. The proposed model manages to achieve reconstruction garments with realistic creases.
        </p>
          </div>
          <div>
            <img src="./static/images/recon.png" alt="method" class="center">
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
    <!-- License. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">License</h2>
        <div class="content has-text-justified">
        <p>
            Models and data along with their corresponding derivatives are used for non-commercial research and education purposes only. You agree not copy, sell, trade, or exploit the model for any commercial purposes. In any published research using the models or Dataset, you cite the following paper:
        </p>
       <p>
           Design2Cloth: 3D Cloth Generation from 2D Masks, Jiali Zheng, RA Potamias and S. Zafeiriou, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June, 2024        </p>
          </div>
      </div>
    </div>
  </div>
</section>
  

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Zheng_2024_CVPR,
      author    = {Zheng, Jiali and Potamias, Rolandos Alexandros and Zafeiriou, Stefanos},
      title     = {Design2Cloth: 3D Cloth Generation from 2D Masks},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2024},
      pages     = {1748-1758}
  }
</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
